{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mathematical exercises\n",
    "\n",
    "Solutions to the following exercises may be either typed into the submitted Jupyter notebook, or handwritten solutions may be scanned and submitted as a separate PDF file.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 1** (3 points): Problem 2.4 from the PRML textbook.\n",
    "\n",
    "**Exercise 2** (5 points): Problem 2.18 from the PRML textbook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expectation and variance of independent random variables\n",
    "\n",
    "In class, we showed that the outcome of a single coin flip is characterized by the Bernoulli distribution, for which $\\mathbb{E}[x] = \\mu$ and $\\mathrm{Var}[x] = \\mu (1 - \\mu)$, where $x=1$ corresponds to heads and $x=0$ corresponds to tails. Similarly, in the first exercise above we showed that the outcome of $N$ independent coin flips is characterized by the binomial distribution, for which $\\mathbb{E}[x] = N\\mu$ and $\\mathrm{Var}[x] = N\\mu (1 - \\mu)$.\n",
    "\n",
    "**Exercise 3** (4 points): Let $\\sum_{n=1}^N x_n$ be a sum of random variables. Show that, when the random variables are independent, the above results are general, i.e. that $\\mathbb{E}[\\sum_n x_n] = \\sum_n \\mathbb{E}[x_n]$ and $\\mathrm{Var}[\\sum_n x_n] = \\sum_n \\mathrm{Var}[x_n]$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  The Central Limit Theorem for the binomial distribution\n",
    "\n",
    "In class, we focused on the binomial distribution, which describes discrete variables, as well as the Gaussian (aka normal) distribution, which describes continuous variables. One reason, among zillions, for why the Gaussian function is useful and ubiquitous is because of the Central Limit Theorem, which states that, under some mild assumptions, a sum of a large number of random variables (or, equivalently, the mean, which is just the sum divided by the number of variables) tends to be normally distributed, even if the variables themselves do not come from a normal distribution.\n",
    "\n",
    "Here, we will show that the binomial distribution becomes a normal distribution when the number of samples becomes large. Recall that a variable $m$ drawn from the binomial distribution $\\mathrm{Bin}(m | N, \\mu)$ describes the number of observations in which a binary variable takes the value 1, given that there are $N$ total observations, and each observation gives 1 with probability $\\mu$ (or 0 otherwise). If we let $m=xN$, then $x$ is a random variable describing the fraction of observations in which 1 is observed.\n",
    "\n",
    "Because $x$ is an average of $N$ random binary variables, we expect the Central Limit Theorem to apply. In the two exercises that follow, we will show that $p(x) = \\mathrm{Bin}(xN | N, \\mu)$ becomes a normal distribution as $N \\to \\infty$.\n",
    "\n",
    "**Exercise 4a** (2 points): Use Stirling's approximation $N! \\approx N(\\ln N - 1)$ (valid for $N \\gg 1$) to show that $p(x) \\propto \\exp[N f(x)]$, where $f(x)$ is independent of $N$, and derive $f(x)$.\n",
    "\n",
    "**Exercise 4b** (2 points). As $N \\to \\infty$, we can apply the method of steepest descent, which means that the exponential in $p(x)$ will be vanishingly small except for values of $x$ very close to the maximum of $f(x)$. Solve for $x^*$ which maximizes $f(x)$ and perform a Taylor expansion to second order, leading to $p(x) = \\exp[-\\frac{1}{2\\sigma^2}(x - x^*)^2]$ (we aren't worried about the normalization in front of the exponent). What are $x^*$ and $\\sigma$? How are they related to the mean and variance of the binomial distribution that we started with? This relation turns out to be a general one, applying to other distributions as well as the binomial distribution.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coding exercises\n",
    "\n",
    "In the exercises that follow, we will use simulated data to check the predictions of the Central Limit Theorem.\n",
    "\n",
    "Reminder: Once your notebook is complete, you should restart the kernel, run all of the cells in order, and make sure that no errors occur. Notebooks that run successfully without errors will be awarded one extra credit point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 1** (3 points): Let $\\{m_1, m_2, \\ldots, m_M\\}$ be random variables drawn from the binomial distribution $\\mathrm{Bin}(m | N, \\mu)$, and let $x_i = m_i/N$. Plot two histograms of the distributions of $x_i$: one with $N=20$ and another with $N=10,000$. In both plots, use $M = 10,000$ and $\\mu = 0.8$. The function `np.random.binomial()` may be useful. Give each plot appropriate axes labels and title. Describe how the two distributions appear to differ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Solution ##\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 2** (3 points): Create a function `f(M, N, mu)` that takes $M$, $N$, and $\\mu$ (as defined in the previous exercise) as inputs and returns the variance of the distribution of $M$ random variables $x_i \\sim \\text{Bin}(N,\\mu)$ (i.e. the distribution plotted in the previous exercise). Plot this variance on a log-log plot for various values of `N`, with `M=10000` and `mu=0.8`. In the same figure, also plot the result you obtained for the variance in the mathematical exercises on the Central Limit Theorem above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Solution ##\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
