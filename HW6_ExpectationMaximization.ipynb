{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mathematical exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 1** (3 points): Problem 9.4 in the PRML textbook.\n",
    "\n",
    "**Exercise 2**: (3 points): Problem 9.14 in the PRML textbook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coding exercises\n",
    "\n",
    "In the exercises below, we will implement the expectation maximization (EM) algorithm, applying it to a mixture of Gaussians model to describe clustering in data.\n",
    "\n",
    "Reminder: Once your notebook is complete, you should restart the kernel, run all of the cells in order, and make sure that no errors occur. Notebooks that run successfully without errors will be awarded one extra credit point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mixture model for synthetic data\n",
    "\n",
    "To begin, we'll generate some synthetic data from a mixture of Gaussians model. Each data point is generated from one of two multimodal Gaussian distributions, but the points aren't given any labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'x2')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Make some fake data.\n",
    "\n",
    "d = 2  # dimensionality of data\n",
    "n = 100  # total number of data points\n",
    "\n",
    "# Generate means (we'll use underscores to denote the true parameters, which we'll try to infer below):\n",
    "mu1_ = np.ones(d)\n",
    "mu2_ = -np.ones(d)\n",
    "\n",
    "# Generate covariance matrices as linear combinations of outer products of basis vectors:\n",
    "vecs = np.random.randn(d,d)\n",
    "Sigma1_ = np.sum([(0.5+np.random.rand())*np.outer(vecs[i], vecs[i]) for i in range(d)], axis=0)\n",
    "Sigma2_ = np.sum([(0.5+np.random.rand())*np.outer(vecs[i], vecs[i]) for i in range(d)], axis=0)\n",
    "\n",
    "# The mixture probabilities:\n",
    "pi1_, pi2_ = 0.4, 0.6 \n",
    "\n",
    "# For each data point, choose a cluster that it belongs to and generate its location:\n",
    "x = np.zeros((0,d))\n",
    "labels = []  # we won't use cluster labels for fitting, but we'll use it to check the model below\n",
    "for ii in range(n):\n",
    "    if np.random.rand() < pi1_:\n",
    "        x = np.vstack((x, np.random.multivariate_normal(mu1_, Sigma1_)))\n",
    "        labels.append(0)\n",
    "    else:\n",
    "        x = np.vstack((x, np.random.multivariate_normal(mu2_, Sigma2_)))\n",
    "        labels.append(1)\n",
    "\n",
    "# Plot the data:\n",
    "plt.figure(figsize=(4,4))\n",
    "plt.plot(x[:,0], x[:,1], 'o')\n",
    "plt.xlabel('x1')\n",
    "plt.ylabel('x2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 1** (5 points): Implement the EM algorithm to find the maximum likelihood solution for a mixture of Gaussians model with $K=2$ applied to the data above. Report the inferred values of the means and mixture probabilities. Plot the value of the log likelihood at each step in the iteration and show that it converges. Finally, plot the data on top of a contour plot illustrating the expected distribution under the fitted model. The algorithm should be implemented from scratch, with only basic Numpy functions being used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Solution ##\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 2** (3 points): Now fit the same data the easy way using `GaussianMixture` from the `sklearn` library. Report the extimated mean vectors and mixture probabilities, as well as the fraction of cluster labels that are correctly predicted by the model by comparing the model's predicted cluster labels with the vector `labels` that we defined above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.mixture import GaussianMixture\n",
    "\n",
    "## Solution ##\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mixture model for the Iris dataset\n",
    "\n",
    "In class we explored the Iris dataset, which quantifies four characteristics of three different flower subspecies. Let's load that dataset again and look at some of its properties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features: \n",
      " ['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n",
      "Targets: \n",
      " ['setosa' 'versicolor' 'virginica']\n",
      "n_samples, n_features:  (150, 4)\n",
      "X data: \n",
      " [[5.1 3.5 1.4 0.2]\n",
      " [4.9 3.  1.4 0.2]\n",
      " [4.7 3.2 1.3 0.2]]\n",
      "y data: \n",
      " [0 0 0]\n"
     ]
    }
   ],
   "source": [
    "# Load the Iris dataset:\n",
    "from sklearn.datasets import load_iris\n",
    "data = load_iris()  # data is a dictionary containing lots of things\n",
    "\n",
    "# List of the features and targets being measured:\n",
    "print('Features: \\n', data['feature_names'])\n",
    "print('Targets: \\n', data['target_names'])\n",
    "\n",
    "# The input data (each row gives measurements of the features listed above):\n",
    "X_iris = data['data']\n",
    "n_samples, n_features = np.shape(data['data'])\n",
    "print('n_samples, n_features: ', (n_samples, n_features))\n",
    "\n",
    "# The target data (subspecies identity):\n",
    "y_iris = data['target']\n",
    "\n",
    "# Print the first few samples of x and y data:\n",
    "print('X data: \\n', X_iris[:3,:])\n",
    "print('y data: \\n', y_iris[:3])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 3** (4 points): Fit Gaussian mixture models to this data using the `GaussianMixture` class as above, now for several different values of $K$ (number of clusters). After reading the documentation of this class, plot, for each value of $K$, the model's log likelihood, as well as the Bayesian information criterion (BIC), which is the same as the negative log likelihood but also penalizes the number of parameters in the model (note that lower BIC scores are better; see the textbook or Wikipedia for more details). Give an explanation for why these curves look the way that they do. Based on the results, what number of clusters best describes the data? In general, how does the number of parameters in the mixture model depend on the number of features $M$ and the number of clusters $K$?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Solution ##\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
