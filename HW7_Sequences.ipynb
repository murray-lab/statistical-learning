{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d889a402",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aafb48e",
   "metadata": {},
   "source": [
    "# Mathematical exercises\n",
    "\n",
    "**Exercise 1** (4 points): Problem 13.5 in the PRML textbook.\n",
    "\n",
    "**Exercise 2** (2 points): Problem 13.6 in the PRML textbook.\n",
    "\n",
    "**Exercise 3** (4 points): Use the two basic rules of probability (the \"sum and product rules\" from PRML Chapter 2) to prove the following for an HMM (PRML Eq. (13.24)):\n",
    "$\n",
    "p(\\mathbf{X}|\\mathbf{z}_n) = p(\\mathbf{x}_1, \\ldots, \\mathbf{x}_n | \\mathbf{z}_n)\n",
    "p(\\mathbf{x}_{n+1}, \\ldots, \\mathbf{x}_N | \\mathbf{z}_n).\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89214a1f",
   "metadata": {},
   "source": [
    "# Coding exercises\n",
    "\n",
    "In this notebook we will create some synthetic data and fit it with a hidden Markov model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ece166e",
   "metadata": {},
   "source": [
    "To begin, we will generate a synthetic time series of data. The latent variable `z` in our model will be binary, where `z[n]=0` corresponds to the first latent state at timestep `n`, and `z[n]=1` corresponds to the other latent state. The transition probabilities between `z[n]` and `z[n+1]` are described by the 2x2 matrix `trans_prob`. At each `n`, an observation `x[n]` is drawn from a normal distribution with mean and covariance `(m1, s1)` (if `z[n]=0`) or `(m2, s2)` (if `z[n]=1`).\n",
    "\n",
    "The block of code below defines the parameters for our generating model. We will later try to estimate these parameters given the observations `x`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "b4eabf15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Means and covariances for the two Gaussian emission distributions:\n",
    "m1 = np.array([1,1])\n",
    "m2 = np.array([-1,-1])\n",
    "m = [m1, m2]\n",
    "s1 = 0.5*np.eye(2)\n",
    "s2 = 0.5*np.eye(2)\n",
    "s = [s1, s2]\n",
    "\n",
    "# trans_prob[i,j] is the probability of transitioning from state i to state j:\n",
    "trans_prob = np.array([[0.8, 0.2], [0.1, 0.9]])\n",
    "#trans_prob = np.array([[0.5, 0.5], [0.5, 0.5]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c20b620",
   "metadata": {},
   "source": [
    "**Exercise 1** (4 points): Using the parameters defined above, generate synthetic data `z` (a 1D array of length `n_steps`) and `x` (A 2D array of shape `n_steps` by 2, where 2 is the dimensionality of each observation). Make a plot of each of these variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e19e554",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Solution ##\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2d11145",
   "metadata": {},
   "source": [
    "Our goal now will be to pretend that we don't know the parameters or latent states and infer these using a hidden Markov model. We'll use the `hmmlearn` package, which you may need to install before proceeding. To install the package, try running `pip install hmmlearn` in the terminal, or read the documentation here: https://github.com/hmmlearn/hmmlearn.\n",
    "\n",
    "Let's import the package we'll need and read the documentation for `GaussianHMM`, a class which fits an HMM to data assuming Gaussian emissions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "e208f97f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hmmlearn import hmm\n",
    "\n",
    "hmm.GaussianHMM?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "155cf4e2",
   "metadata": {},
   "source": [
    "**Exercise 2** (4 points): Follow the example given at the following link to fit the data with an HMM, assuming two latent states (`n_components=2`):\n",
    "https://hmmlearn.readthedocs.io/en/stable/tutorial.html#training-hmm-parameters-and-inferring-the-hidden-states\n",
    "\n",
    "Compute the sequence of latent states inferred by the model, calling this `z_pred`, and compare this to the true sequence of hidden states by computing the correlation coefficient:\n",
    "$$\n",
    "\\rho = \\frac{\\frac{1}{N}\\sum_{n=1}^N(z_n - E(z)) (z^\\mathrm{pred}_n - E(z^\\mathrm{pred}))}\n",
    "{\\sqrt{\\mathrm{Var}[z] \\mathrm{Var}[z^\\mathrm{pred}]}}.\n",
    "$$\n",
    "To check that your result makes sense, also print the model parameters (means and covariance matrices for the two hidden states, as well as the transition probability matrix) and show that they are similar (hopefully to within ~10% or so) to the parameters from the model that generated the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "188fd31f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Solution ##\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb2b2741",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
